{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwMiwSTTBbVs"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctjBO2kHBVoT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "537887a0-7c2a-4d46-b1a1-39dd726fc55e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RceimujwBgFJ"
      },
      "outputs": [],
      "source": [
        "# Access Google Drive Folder\n",
        "import os\n",
        "COLAB_PATH = \"/content/gdrive\"\n",
        "os.chdir(COLAB_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXGpYKLcBkl1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3c54cd6-f286-44a6-b7bb-f664c6e25786"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: could not create work tree dir 'yolov7': Operation not supported\n"
          ]
        }
      ],
      "source": [
        "# Clone YOLOv7\n",
        "!git clone https://github.com/pHidayatullah/yolov7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHByh54JBlPa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a45ea45d-cede-4afc-9297-6257426cb2b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'yolov7'\n",
            "/content/gdrive/MyDrive/yolov7\n",
            "MyDrive\n"
          ]
        }
      ],
      "source": [
        "# Enter to yolov7 folder\n",
        "%cd yolov7\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFJI0LEtCFYc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36193a29-bf52-4340-e777-2a9c78b3ec39"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# Check GPU\n",
        "import torch\n",
        "\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQupCyE3BoP6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41a17bf8-e85c-4fb6-a5c0-606be8dc8226"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-19 16:22:45--  https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt\n",
            "Resolving github.com (github.com)... 140.82.116.3\n",
            "Connecting to github.com (github.com)|140.82.116.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/b0243edf-9fb0-4337-95e1-42555f1b37cf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241119%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241119T162245Z&X-Amz-Expires=300&X-Amz-Signature=71c9d97e0ed77b6e881f2931d3817117543f2b83546dbe931da5d4d06f372718&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dyolov7.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-11-19 16:22:45--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/b0243edf-9fb0-4337-95e1-42555f1b37cf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241119%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241119T162245Z&X-Amz-Expires=300&X-Amz-Signature=71c9d97e0ed77b6e881f2931d3817117543f2b83546dbe931da5d4d06f372718&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dyolov7.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 75587165 (72M) [application/octet-stream]\n",
            "yolov7.pt: Operation not supported\n",
            "\n",
            "Cannot write to â€˜yolov7.ptâ€™ (Success).\n"
          ]
        }
      ],
      "source": [
        "# Download pretrained weights\n",
        "!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MgMokDFaBpBe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82e21669-8c0a-4bdc-d853-aac8ff84c8d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/gdrive/detect.py': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!python detect.py --weights yolov7.pt --source inference/images/bus.jpg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1QdcvcjRgaE"
      },
      "source": [
        "# Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECcRvK4Ltn92",
        "outputId": "4bb69680-c2da-41cb-d288-03c4a5ffd32e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JyHpTqd9totg"
      },
      "outputs": [],
      "source": [
        "# Access Google Drive Folder\n",
        "import os\n",
        "COLAB_PATH = \"/content/gdrive/\"\n",
        "os.chdir(COLAB_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyZxfmpbtqTm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20c697e8-b653-4d1b-a0d2-70fa299427b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'yolov7'\n",
            "/content/gdrive/MyDrive/yolov7\n",
            "MyDrive\n"
          ]
        }
      ],
      "source": [
        "# Enter to yolov7 folder\n",
        "%cd yolov7\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkNGwrsztvdR"
      },
      "source": [
        "## Detection on Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFWKussntt4I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b651bae-8690-4954-fabc-a33cf95a5ac8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/gdrive/detect.py': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# Detection on Image\n",
        "!python detect.py --weights yolov7.pt --conf-thres 0.5 --img-size 640 --source inference/images/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZfsQKPgRHljj"
      },
      "outputs": [],
      "source": [
        "# Function to Show Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "def showImage(path):\n",
        "  img = mpimg.imread(path)\n",
        "  plt.figure(figsize=(20,20))\n",
        "  plt.axis(\"off\")\n",
        "  plt.imshow(img)\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show Detection Result\n",
        "showImage(\"runs/detect/exp3/horses.jpg\")"
      ],
      "metadata": {
        "id": "6Lt0C6JJsCsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFFrcfy4t0bM"
      },
      "source": [
        "## Detection on Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omS2611kJxxU"
      },
      "outputs": [],
      "source": [
        "# Download Video\n",
        "!gdown https://drive.google.com/uc?id=1pg04n7WWRgiw2qL2Cc9cXhV4x8wlHiQ7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6F84c6pNNHO"
      },
      "outputs": [],
      "source": [
        "# Move to inference folder\n",
        "!mv road.mp4 inference/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-immIBjNiUp"
      },
      "outputs": [],
      "source": [
        "# See the inference folder\n",
        "!ls inference/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q7aG2bDst4DO"
      },
      "outputs": [],
      "source": [
        "# Detection on Video\n",
        "!python detect.py --weights yolov7.pt --conf-thres 0.5 --img-size 640 --source inference/road.mp4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Detection Result Folder\n",
        "!ls runs/detect"
      ],
      "metadata": {
        "id": "GH87LwbDoWYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jDdiLqqRifs"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "wgdN1q3ukZHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Access Google Drive Folder\n",
        "import os\n",
        "COLAB_PATH = \"gdrive/MyDrive\"\n",
        "os.chdir(COLAB_PATH)"
      ],
      "metadata": {
        "id": "LGWOYDHBkZrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Enter to yolov7 folder\n",
        "%cd yolov7\n",
        "!ls"
      ],
      "metadata": {
        "id": "n6ZMLWcakZxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Dataset\n",
        "!ls data/"
      ],
      "metadata": {
        "id": "L3ExnkJGkRkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip Dataset\n",
        "!unzip data/face_mask_dataset.zip -d ./data"
      ],
      "metadata": {
        "id": "Ip-fhHhyJWNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download pre-trained weight for training\n",
        "!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7_training.pt"
      ],
      "metadata": {
        "id": "z36-H05wj6yn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "!python train.py --batch-size 8 --device 0 --data data/face-mask.yaml --img 640 640 --cfg cfg/training/yolov7-face_mask.yaml --weights yolov7_training.pt --name yolov7-face-mask --hyp data/hyp.scratch.custom.yaml --epochs 300"
      ],
      "metadata": {
        "id": "0lBnVwz2nzY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# See the accuracy\n",
        "%load_ext tensorboard\n",
        "\n",
        "%tensorboard --logdir runs/train"
      ],
      "metadata": {
        "id": "qsGaVsTUw-me"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Continue Training"
      ],
      "metadata": {
        "id": "GX-IRJSG3m96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Continue Training\n",
        "!python train.py --batch-size 8 --device 0 --data data/face-mask.yaml --img 640 640 --cfg cfg/training/yolov7-face_mask.yaml --weights runs/train/yolov7-face-mask/weights/last.pt --name yolov7-face-mask --hyp data/hyp.scratch.custom.yaml --epochs 300 --resume"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VZHXjoq3l-0",
        "outputId": "152f9f76-2bd3-4df5-b9f7-129fc8d7e8da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resuming training from ./runs/train/yolov7-face-mask/weights/last.pt\n",
            "YOLOR ðŸš€ 566dacf torch 1.12.1+cu113 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Namespace(adam=False, artifact_alias='latest', batch_size=8, bbox_interval=-1, bucket='', cache_images=False, cfg='', data='data/face-mask.yaml', device='0', entity=None, epochs=300, evolve=False, exist_ok=False, freeze=[0], global_rank=-1, hyp='data/hyp.scratch.custom.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='yolov7-face-mask', noautoanchor=False, nosave=False, notest=False, project='runs/train', quad=False, rect=False, resume=True, save_dir='runs/train/yolov7-face-mask', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=8, upload_dataset=False, v5_metric=False, weights='./runs/train/yolov7-face-mask/weights/last.pt', workers=8, world_size=1)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, paste_in=0.0, loss_ota=1\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 12                -1  1         0  models.common.MP                        []                            \n",
            " 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n",
            " 25                -1  1         0  models.common.MP                        []                            \n",
            " 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 38                -1  1         0  models.common.MP                        []                            \n",
            " 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n",
            " 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n",
            " 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 76                -1  1         0  models.common.MP                        []                            \n",
            " 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n",
            " 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 89                -1  1         0  models.common.MP                        []                            \n",
            " 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n",
            " 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n",
            " 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            "100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            "101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n",
            "102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n",
            "103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n",
            "104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n",
            "105   [102, 103, 104]  1     44944  models.yolo.IDetect                     [3, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n",
            "Model Summary: 415 layers, 37207344 parameters, 37207344 gradients\n",
            "\n",
            "Transferred 566/566 items from ./runs/train/yolov7-face-mask/weights/last.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 95 .bias, 95 conv.weight, 98 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'data/face_mask_dataset/labels/train.cache' images and labels... 640 found, 0 missing, 0 empty, 0 corrupted: 100% 640/640 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'data/face_mask_dataset/labels/val.cache' images and labels... 80 found, 0 missing, 0 empty, 0 corrupted: 100% 80/80 [00:00<?, ?it/s]\n",
            "Image sizes 640 train, 640 test\n",
            "Using 2 dataloader workers\n",
            "Logging results to runs/train/yolov7-face-mask\n",
            "Starting training for 300 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "    61/299     7.62G   0.02933   0.01101  0.004091   0.04443        52       640:  10% 8/80 [00:38<01:39,  1.38s/it]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "    61/299     7.62G    0.0321   0.01081  0.004647   0.04756        59       640:  11% 9/80 [00:38<01:18,  1.11s/it]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "    61/299     7.62G   0.03108   0.01079  0.004102   0.04597        39       640:  15% 12/80 [00:41<01:04,  1.06it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "    61/299     7.63G   0.03107   0.01103  0.003864   0.04596       136       640:  22% 18/80 [00:45<00:44,  1.39it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "    61/299     7.63G   0.03061   0.01068  0.004526   0.04581        75       640:  66% 53/80 [01:08<00:18,  1.48it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "    61/299     7.63G   0.03068   0.01065  0.004223   0.04555       139       640:  84% 67/80 [01:20<00:15,  1.17s/it]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "    61/299     7.63G   0.03088    0.0108   0.00428   0.04596        96       640: 100% 80/80 [01:31<00:00,  1.15s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:   0% 0/5 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 5/5 [00:22<00:00,  4.56s/it]\n",
            "                 all          80         376       0.632       0.691       0.688       0.428\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "    62/299     7.58G   0.03297   0.01185  0.003942   0.04876        49       640:  16% 13/80 [00:07<00:42,  1.59it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "    62/299     7.58G    0.0325   0.01191  0.003746   0.04815        89       640:  21% 17/80 [00:10<00:49,  1.27it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "    62/299     7.58G   0.03153   0.01113  0.003637    0.0463        32       640:  41% 33/80 [00:21<00:29,  1.61it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "    62/299     7.58G   0.03113     0.011  0.003592   0.04572        79       640:  48% 38/80 [00:24<00:28,  1.46it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "    62/299     7.58G    0.0321   0.01082  0.003396   0.04631        63       640:  84% 67/80 [00:42<00:07,  1.65it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "    62/299     7.58G   0.03214   0.01079  0.003351   0.04628        38       640: 100% 80/80 [00:51<00:00,  1.57it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 5/5 [00:02<00:00,  1.87it/s]\n",
            "                 all          80         376       0.684       0.597       0.675       0.421\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "    63/299     7.58G   0.03027   0.01066  0.003736   0.04466        62       640:   9% 7/80 [00:03<00:35,  2.08it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "    63/299     7.58G   0.03303  0.009906  0.003335   0.04627        27       640:  16% 13/80 [00:07<00:40,  1.67it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "    63/299     7.58G   0.03157   0.01041  0.003975   0.04596        75       640:  68% 54/80 [00:35<00:17,  1.50it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "    63/299     7.58G   0.03142   0.01049  0.003858   0.04577        66       640:  75% 60/80 [00:39<00:13,  1.47it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "    63/299     7.58G   0.03116   0.01079  0.003969   0.04592        86       640: 100% 80/80 [00:52<00:00,  1.53it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 5/5 [00:02<00:00,  1.84it/s]\n",
            "                 all          80         376       0.722        0.62        0.72       0.458\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "    64/299     7.58G   0.03137   0.01005  0.004051   0.04547        62       640:  12% 10/80 [00:05<00:41,  1.70it/s]Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tqdm/std.py\", line 1195, in __iter__\n",
            "    for obj in iterable:\n",
            "  File \"/content/gdrive/MyDrive/yolov7/utils/datasets.py\", line 110, in __iter__\n",
            "    yield next(self.iterator)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 681, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1359, in _next_data\n",
            "    idx, data = self._get_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1315, in _get_data\n",
            "    success, data = self._try_get_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1163, in _try_get_data\n",
            "    data = self._data_queue.get(timeout=timeout)\n",
            "  File \"/usr/lib/python3.7/queue.py\", line 179, in get\n",
            "    self.not_empty.wait(remaining)\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 300, in wait\n",
            "    gotit = waiter.acquire(True, timeout)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 616, in <module>\n",
            "    train(hyp, opt, device, tb_writer)\n",
            "  File \"train.py\", line 336, in train\n",
            "    for i, (imgs, targets, paths, _) in pbar:  # batch -------------------------------------------------------------\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tqdm/std.py\", line 1210, in __iter__\n",
            "    self.close()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tqdm/std.py\", line 1316, in close\n",
            "    self.display(pos=0)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tqdm/std.py\", line 1509, in display\n",
            "    self.sp(self.__str__() if msg is None else msg)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tqdm/std.py\", line 350, in print_status\n",
            "    fp_write('\\r' + s + (' ' * max(last_len[0] - len_s, 0)))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tqdm/std.py\", line 343, in fp_write\n",
            "    fp.write(_unicode(s))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tqdm/utils.py\", line 145, in inner\n",
            "    return func(*args, **kwargs)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Face Mask Detection"
      ],
      "metadata": {
        "id": "mFns5lAkRj-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download Image\n",
        "!gdown https://drive.google.com/uc?id=1XhoXpam5K6lCXJ6338Uow6L1P0iPFuNV"
      ],
      "metadata": {
        "id": "NtRt6-zERqG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move to inference folder\n",
        "!mv face-mask.png inference/"
      ],
      "metadata": {
        "id": "zPapgMfrTfvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Detection on Image\n",
        "!python detect.py --weights runs/train/yolov7-face-mask/weights/best.pt --conf-thres 0.5 --img-size 640 --source inference/face-mask.png"
      ],
      "metadata": {
        "id": "n9DktkvtTryh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to Show Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "def showImage(path):\n",
        "  img = mpimg.imread(path)\n",
        "  plt.figure(figsize=(20,20))\n",
        "  plt.axis(\"off\")\n",
        "  plt.imshow(img)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "3pd_PbPNT4Il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "showImage(\"runs/detect/exp3/face-mask.png\")"
      ],
      "metadata": {
        "id": "H_YRDUTFUAJ3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}